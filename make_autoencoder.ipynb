{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os                                                                          \n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"                                       \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"                                             \n",
    "import tensorflow as tf                                                            \n",
    "session_config=tf.ConfigProto(                                                     \n",
    "        gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.3, allow_growth=True), allow_soft_placement=True, log_device_placement=False)\n",
    "sess = tf.Session(config=session_config)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import pickle\n",
    "from skimage import io, transform\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras.backend as K\n",
    "from keras import layers, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.layers import Conv2D, BatchNormalization, Activation, ZeroPadding2D, Conv2DTranspose, UpSampling2D, Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# address = '/all/media/hdd1/georgy'\n",
    "# def fix_address(adr):\n",
    "#     fix_adr = list(adr)\n",
    "#     fix_adr[0]=address\n",
    "#     fix_adr=''.join(fix_adr)\n",
    "#     return fix_adr\n",
    "# with open('/all/media/hdd1/georgy/checkpoints/CubeChangeClassName_v1.2_558b0595e105de8cad848fa41ae1bc87de6713ec62906783b57858e9.pkl','rb') as f:\n",
    "#     data = pickle.load(f)\n",
    "\n",
    "# patch_dir_name = 'patches'\n",
    "# if not os.path.isdir(patch_dir_name):\n",
    "#     os.makedirs(patch_dir_name)\n",
    "\n",
    "# sizes = []\n",
    "# for i, example in enumerate(data['data_description']):\n",
    "#     image = io.imread(fix_address(example['image_path']))\n",
    "#     for j, obj in enumerate(example['objects']):\n",
    "#         x1,y1 = np.min(obj['polygons']['front'], axis=0).astype(int)\n",
    "#         x2,y2 = np.max(obj['polygons']['front'],axis=0).astype(int)\n",
    "#         patch = image[y1:y2,x1:x2].copy()\n",
    "#         io.imsave(patch_dir_name + '/{}_{}.jpg'.format(i,j), patch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define loss pad and crop func "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth=1\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "def padd_to_16fit(inputs):\n",
    "    '''\n",
    "    zero pad input tensor to shape multiple to 16\n",
    "    '''\n",
    "    shape = K.shape(inputs) #batch,h,w,channel\n",
    "    inputs = K.switch(K.equal(shape[2]%32,0),\n",
    "                            inputs,\n",
    "                            tf.pad(inputs,((0,0), #batch\n",
    "                                           (0,0), #h\n",
    "                                           ((32-shape[2]%32)//2,(32-shape[2]%32)//2+(32-shape[2]%32)%2), #w\n",
    "                                           (0,0)))) #channel\n",
    "    inputs = K.switch(K.equal(shape[1]%32,0),\n",
    "                            inputs,\n",
    "                            tf.pad(inputs,((0,0),\n",
    "                                          ((32-shape[1]%32)//2,(32-shape[1]%32)//2+(32-shape[1]%32)%2),\n",
    "                                          (0,0),\n",
    "                                          (0,0))))\n",
    "    return inputs\n",
    "\n",
    "def crop_to_16fit(arg):\n",
    "    '''\n",
    "    crop output tensor to initial shape (undo result of padd_to_16fit() )\n",
    "    '''\n",
    "    [conv10, inputs] = arg\n",
    "    shape = K.shape(inputs) #batch,h,w,channel\n",
    "    conv10 = tf.cond(K.equal(shape[1]%32,0),\n",
    "                            lambda: conv10,\n",
    "                            lambda: tf.slice(conv10,(0,(32-shape[1]%32)//2,0,0),\n",
    "                                           (-1,shape[1],-1,-1)),\n",
    "                    name = 'vertical_crop') \n",
    "    conv10 = tf.cond(K.equal(shape[2]%32,0),\n",
    "                            lambda: conv10,\n",
    "                            lambda: tf.slice(conv10,(0,0,(32-shape[2]%32)//2,0),\n",
    "                                           (-1,-1,shape[2],-1)),\n",
    "                    name = 'horizontal_crop')\n",
    "    return conv10\n",
    "\n",
    "def make_voluem(inputs):\n",
    "    x_flatten, x_shaped = inputs\n",
    "    shape = tf.shape(x_shaped)\n",
    "    tf.assert_equal(shape[-1], tf.shape(x_flatten)[-1])\n",
    "    ones_voluem = tf.ones([shape[0], shape[1], shape[2], HIDDEN_DEPTH], tf.float32)\n",
    "    return x_flatten*ones_voluem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define  upsample layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
    "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: default 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    \"\"\"\n",
    "    filters1, filters2, filters3 = filters\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    conv_name_base = 'upsample_res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'upsample_bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1), name=conv_name_base + '2a')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size,\n",
    "               padding='same', name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    x = layers.add([input_tensor, x])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
    "    \"\"\"A block that has a conv layer at shortcut.\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: default 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "        strides: Strides for the first conv layer in the block.\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    Note that from stage 3,\n",
    "    the first conv layer at main path is with strides=(2, 2)\n",
    "    And the shortcut should have strides=(2, 2) as well\n",
    "    \"\"\"\n",
    "    filters1, filters2, filters3 = filters\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    conv_name_base = 'upsample_res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'upsample_bn' + str(stage) + block + '_branch'\n",
    "    up_name_base = 'upsample_upsample' + str(stage) + block + '_branch'\n",
    "    \n",
    "    x = UpSampling2D(strides, name=up_name_base + '2a')(input_tensor)\n",
    "    x = Conv2D(filters1, (1, 1), strides=(1, 1),\n",
    "               name=conv_name_base + '2a')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size, padding='same',\n",
    "               name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "        \n",
    "    shortcut = UpSampling2D(strides, name=up_name_base + '1')(input_tensor)\n",
    "    shortcut = Conv2D(filters3, (1, 1), strides=(1, 1),\n",
    "                      name=conv_name_base + '1')(shortcut)\n",
    "    shortcut = BatchNormalization(axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
    "\n",
    "    x = layers.add([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  set nontrainable layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_trainable(model):\n",
    "    for layer in model.layers:\n",
    "        if not layer.name.startswith('upsample'):\n",
    "            layer.trainable = False\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_DEPTH = 10\n",
    "\n",
    "inputs = keras.layers.Input((None, None, 3))\n",
    "x = keras.layers.Lambda(padd_to_16fit, name='pad', output_shape=(None,None,3))(inputs)\n",
    "resnet_backbone = ResNet50(include_top=False, weights='imagenet', input_tensor=x, input_shape=None, pooling='max')\n",
    "x_shaped = resnet_backbone.get_layer(index=-3).output\n",
    "x = resnet_backbone.output\n",
    "x = keras.layers.Dense(HIDDEN_DEPTH)(x)\n",
    "\n",
    "x = keras.layers.Lambda(make_voluem)([x, x_shaped])\n",
    "\n",
    "bn_axis = 3 # tf order\n",
    "x = conv_block(x, 3, [512, 512, 512], stage=5, block='a')\n",
    "x = identity_block(x, 3, [512, 512, 512], stage=5, block='b')\n",
    "x = identity_block(x, 3, [512, 512, 512], stage=5, block='c')\n",
    "\n",
    "x = conv_block(x, 3, [256, 256, 256], stage=4, block='a')\n",
    "x = identity_block(x, 3, [256, 256, 256], stage=4, block='b')\n",
    "x = identity_block(x, 3, [256, 256, 256], stage=4, block='c')\n",
    "x = identity_block(x, 3, [256, 256, 256], stage=4, block='d')\n",
    "x = identity_block(x, 3, [256, 256, 256], stage=4, block='e')\n",
    "x = identity_block(x, 3, [256, 256, 256], stage=4, block='f')    \n",
    "\n",
    "x = conv_block(x, 3, [256, 128, 128], stage=3, block='a')\n",
    "x = identity_block(x, 3, [256, 128, 128], stage=3, block='b')\n",
    "x = identity_block(x, 3, [256, 128, 128], stage=3, block='c')\n",
    "x = identity_block(x, 3, [256, 128, 128], stage=3, block='d')\n",
    "\n",
    "x = conv_block(x, 3, [64, 64, 64], stage=2, block='a', strides=(2, 2))\n",
    "x = identity_block(x, 3, [64, 64, 64], stage=2, block='b')\n",
    "x = identity_block(x, 3, [64, 64, 64], stage=2, block='c')\n",
    "\n",
    "x = UpSampling2D((2,2), name = 'upsample_last_upsample')(x)\n",
    "x = Conv2D(3, (3, 3), padding='same', name='upsample_conv1')(x)\n",
    "x = BatchNormalization(axis=bn_axis, name='upsample_bn_conv1')(x)\n",
    "x = Activation('tanh', name = 'upsample_final_activation')(x)\n",
    "\n",
    "x = keras.layers.Lambda(crop_to_16fit, name='crop', output_shape=(None,None,3))([x, inputs])\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[x])\n",
    "model = set_trainable(model) # not train initial resnet\n",
    "model.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss, metrics=[dice_coef])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = io.imread('../patches/1001_0.jpg').astype(np.float)\n",
    "input_image = preprocess_input(input_image, mode='tf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(236, 673, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "small_image = transform.rescale(input_image, scale = 0.1, order = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 67, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "model.fit(small_image[None,...],small_image[None,...],epochs=10)\n",
    "pred = model.predict(input_image[None,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(input_image - np.min(input_image))\n",
    "ax2.imshow(res[0]- np.min(res[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_image = np.random.randn(260,260,3)\n",
    "# init_op = tf.global_variables_initializer()\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(init_op)\n",
    "#     res = sess.run(x, feed_dict={inputs: [input_image]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from skimage.transform import rescale\n",
    "from skimage.io import imread\n",
    "import os\n",
    "import re\n",
    "\n",
    "images_folder = '../patches/'\n",
    "files_list = next(os.walk(images_folder))[2]\n",
    "\n",
    "examples_num = len(files_list) \n",
    "random.seed(17)\n",
    "random.shuffle(files_list)\n",
    "train_set = files_list[:int(examples_num*0.97)]\n",
    "train_num = len(train_set)\n",
    "val_set = files_list[int(examples_num*0.97):]\n",
    "val_num = len(val_set)\n",
    "\n",
    "def data_generator(examples, batch_size=1): #examples is train or val\n",
    "    while 1:\n",
    "        random.shuffle(examples)\n",
    "        images_batch = []\n",
    "        batch_count = 0\n",
    "        for file_name in examples:\n",
    "            batch_count+=1\n",
    "            image = imread(images_folder + file_name)\n",
    "            image = image.astype(np.float32)\n",
    "            image = preprocess_input(image, mode='tf')\n",
    "            images_batch.append(image)\n",
    "            if batch_count==batch_size:\n",
    "                images_batch = np.array(images_batch) #TODO variable size images in batch\n",
    "                yield images_batch, images_batch\n",
    "                images_batch = []\n",
    "                lables_batch = []\n",
    "                batch_count=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "log_dir = 'log/'\n",
    "if not os.path.isdir(log_dir):\n",
    "    os.mkdir(log_dir)\n",
    "list_log_dir = os.listdir(log_dir)\n",
    "if list_log_dir == []:\n",
    "    log_dir = log_dir + '/0'\n",
    "    os.makedirs(log_dir)\n",
    "else:\n",
    "    log_dir = log_dir+'/{}'.format(np.max([int(i) for i in list_log_dir])+1)\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  start learing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import  TensorBoard\n",
    "from  keras.callbacks import ModelCheckpoint\n",
    "batch_size=1\n",
    "model.fit_generator(generator=data_generator(train_set, batch_size),\\\n",
    "                    epochs=10,steps_per_epoch=train_num/batch_size,\\\n",
    "                    validation_data = data_generator(val_set, batch_size),\\\n",
    "                    validation_steps = val_num/batch_size,\\\n",
    "                    callbacks = [TensorBoard(log_dir = log_dir),\\\n",
    "                                 ModelCheckpoint(filepath = 'learned_model_{val_loss:.2f}.hdf5',\\\n",
    "                                                 save_best_only = True, monitor = 'val_dice_coef',mode='max')])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
